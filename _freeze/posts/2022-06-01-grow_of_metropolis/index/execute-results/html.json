{
  "hash": "80909d966db682be54baf1f6b601864c",
  "result": {
    "markdown": "---\ntitle: \"Grow of Metropolis\"\ncategories: [\"Python\"]\ntags: [\"python\", \"geocoding\"]\ntoc: true\n---\n\n\n## About\n\nAims:\n\n1.  FIlter out the data localisation where people are supposed to live in (cities; villages etc)\n\n2.  Select cities which are metropolis based on population on external source\n\n3.  Write a script which will ascribe metropolis to a city. Additionally model a process of consecutive cities which would be ascribed to the city bearing in mind that city will grow thanks to this process.\n\n[Data Source](http://www.geonames.org/)\n\n[Documentation](http://www.geonames.org/export/codes.html)\n\n## Preparing environment\n\nSetting default markdown option responsible of code chunk behaviour.\n\n\n\n\n\nFirstly I choose prefered python environment on which I have installed useful libraries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\nSys.setenv(RETICULATE_PYTHON = \"/Users/lrabalski1/miniforge3/envs/everyday_use/bin/python\")\nreticulate::py_config()\n## python:         /Users/lrabalski1/miniforge3/envs/everyday_use/bin/python\n## libpython:      /Users/lrabalski1/miniforge3/envs/everyday_use/lib/libpython3.8.dylib\n## pythonhome:     /Users/lrabalski1/miniforge3/envs/everyday_use:/Users/lrabalski1/miniforge3/envs/everyday_use\n## version:        3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:21:17)  [Clang 11.1.0 ]\n## numpy:          /Users/lrabalski1/miniforge3/envs/everyday_use/lib/python3.8/site-packages/numpy\n## numpy_version:  1.21.4\n## \n## NOTE: Python version was forced by RETICULATE_PYTHON\n\nmyenvs=conda_list()\nenvname=myenvs$name[4]\nuse_condaenv(envname, required = TRUE)\n\n```\n:::\n\n\n\n\n\n\nBellow I present two function:\n\n-   radius - function which based on city population is calculating a radius within which city is able to absorb cities from this range\n\n-   \\_calcualate_metrocity_impact - calculate impact on metrocity on given city\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef radius(population):\n    METRO_CITY_POPULATION_CONSTANT = -1/1443000\n    MIN_METRO_CITY_RADIUS = 10\n    MAX_METRO_CITY_RADIUS = 100 - MIN_METRO_CITY_RADIUS\n    return MIN_METRO_CITY_RADIUS + MAX_METRO_CITY_RADIUS * (1 - np.exp(METRO_CITY_POPULATION_CONSTANT *  population))\n\ndef _calcualate_metrocity_impact(max_radius, distance_to_metro_city):\n    METRO_CITY_POWER_CONSTANT = -1.4\n    impact = np.exp(METRO_CITY_POWER_CONSTANT  * distance_to_metro_city / max_radius)\n    return impact\n```\n:::\n\n\nFunction responsible for calculating distances between 2 points on earth surface.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n#https://towardsdatascience.com/heres-how-to-calculate-distance-between-2-geolocations-in-python-93ecab5bbba4\ndef haversine_distance_code(lat1, lon1, lat2, lon2):\n    r = 6371\n    phi1 = np.radians(lat1)\n    phi2 = np.radians(lat2)\n    delta_phi = np.radians(lat2 - lat1)\n    delta_lambda = np.radians(lon2 - lon1)\n    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n    res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)))\n    return np.round(res, 2)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndf= pd.read_csv(file_path_name, sep=\"\\t\", \n                names=['geonameid','name','asciiname','alternatenames','latitude','longitude','feature class','feature code','country code','cc2','admin1 code','admin2 code','admin3 code','admin4 code','population','elevation','dem','timezone','modification date',])\n\n```\n:::\n\n\nDataset readme states that column feature classes contains level information of:\n\nA: country, state, region,...\n\nH: stream, lake, ...\n\nL: parks,area, ...\n\nP: city, village,...\n\nR: road, railroad\n\nS: spot, building, farm\n\nT: mountain,hill,rock,...\n\nU: undersea\n\nV: forest,heath,...\n\nWe will be interested on object of level P, and maybe A.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport requests\n\nurl = 'http://www.geonames.org/export/codes.html'\nhtml = requests.get(url).content\ndf_list = pd.read_html(html)\ndf_legend = df_list[-1]\ndf_legend = df_legend.rename(columns={df_legend.columns[0]: 'feature code',\n                                     df_legend.columns[1]: 'short  descr',\n                                     df_legend.columns[2]: 'long descr'})\ndf_legend = pd.merge(df[['feature code','feature class']].drop_duplicates(),df_legend, on='feature code')\ndf_legend\n##     feature code  ...                                         long descr\n## 0           PPLQ  ...                                                NaN\n## 1            STM  ...  a body of running water moving to a lower leve...\n## 2           HLLS  ...  rounded elevations of limited extent rising ab...\n## 3            CNL  ...                          an artificial watercourse\n## 4            PPL  ...  a city, town, village, or other agglomeration ...\n## ..           ...  ...                                                ...\n## 186          BCN  ...                 a fixed artificial navigation mark\n## 187         HSEC  ...  a large house, mansion, or chateau, on a large...\n## 188          RES  ...  a tract of public land reserved for future use...\n## 189         STNR  ...  a facility for producing and transmitting info...\n## 190         BLDA  ...  a building containing several individual apart...\n## \n## [191 rows x 4 columns]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndf = df[df['feature class'].isin(['P','A'])]\ndf_check = pd.merge(df,df_legend, on=['feature code','feature class'])\n\n# sorting by the biggest objects I can see that those are cities\ndf_check[df_check['feature class']=='P'].sort_values('population', ascending=False).head(5)\n\n# administrative object located in object of level P\ndf_check[df_check['feature class']=='A'].sort_values('population', ascending=False).head(5)\n\n#z tej tabeli wynika, ze PPLX to sekcje zaludnionych miejsc, sa to ulice, dzielnice, wiec wykluczam, sa czescia miast\ndf_check[['feature class','feature code', 'short  descr']].drop_duplicates()\n\n#finalnie musze skupic sie na na obu klasach, jednoczesnie usuwajac duplikaty\ndf = df[(df['feature class'].isin(['P'])) & \n        (df.population != 0) & \n        ~(df['feature code'].isin(['PPLX']))].drop_duplicates('name')\n\n\ndf.index.name = 'city_id'\ndf.reset_index(inplace=True)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndf.groupby(['feature class','feature code']).agg({'population': ['mean', 'min', 'max']})\n##                               population                  \n##                                     mean      min      max\n## feature class feature code                                \n## P             PPL           3.238169e+03        5   244969\n##               PPLA          3.652322e+05   118433   768755\n##               PPLA2         3.543081e+04     5696   226794\n##               PPLA3         5.619329e+03      110   248125\n##               PPLC          1.702139e+06  1702139  1702139\n##               PPLF          1.750000e+02      175      175\n```\n:::\n\n\n## Metropolis in Poland\n\n[wikipedia](https://pl.wikipedia.org/wiki/Obszar_metropolitalny) Warszawa, Katowice, Kraków, Łódź, Trójmiasto, Poznań, Wrocław, Bydgoszcz, Szczecin, Lublin.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf_metropolie = df[df.name.isin(\n    ['Warsaw','Katowice','Kraków','Łódź',\n     'Gdańsk','Gdynia',#'Trójmiasto',\n     'Poznań','Wrocław','Bydgoszcz','Szczecin','Lublin'])][\n    ['city_id','name','population','latitude','longitude']]\ndf_metropolie['iteration']=0 \n#df_metropolie['radius'] = radius(df_metropolie['population'])\ndf_metropolie=df_metropolie.add_suffix('_metro')\ndf_metropolie\n##       city_id_metro name_metro  ...  longitude_metro  iteration_metro\n## 188            3191     Warsaw  ...         21.01178                0\n## 917           12873     Lublin  ...         22.56667                0\n## 1734          25287    Wrocław  ...         17.03333                0\n## 1916          27732   Szczecin  ...         14.55302                0\n## 2279          32047     Poznań  ...         16.92993                0\n## 2654          36976       Łódź  ...         19.47395                0\n## 2774          38634     Kraków  ...         19.93658                0\n## 2889          40299   Katowice  ...         19.02754                0\n## 3089          43232     Gdynia  ...         18.53188                0\n## 3090          43241     Gdańsk  ...         18.64912                0\n## 3298          45802  Bydgoszcz  ...         18.00762                0\n## \n## [11 rows x 6 columns]\n```\n:::\n\n\n## metropolis absorption algorithm\n\n### Instruction\n\n1.  stworze id kolumne z indeksem\n\n2.  zlacze tabele z metropoliami i wszystkimi miastami im do tej pory przypisanymi, wylicze zagregowana ludnosc oraz promien metropoli\n\n3.  croos joinuje do kazdego miasta bez przypisanej metropolii tabele z metropolia\n\n4.  wylicze odleglosc miejscowosci od metropoli i pozbede sie tych wierszy ktore sa poza promieniem\n\n5.  dla pozostalych miejscowosci wylicze moc metropolii\n\n6.  zrobie slice max groupujac po id miejscowosci pozostawiajc metropolie wchlaniajaca - tak powstanie tabela incrementalna do ktorej potem bede rbindowal nastepne tego typu tabele\n\n7.  w obu tabelach powstanie tabele z indeksem mowiacy o n-iteracji z jakiej pochodzi przypisanie miejscowosci do metropolii oraz stan populacji\n\n8.  wszystko zamkne w lupie while ktory bedzie wykonywany tak dlugo jak zostanie odnotowany przyrost w tabeli incrementalnej\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf_cities = df[['city_id','name','population','latitude','longitude']]\ndf_cities = df_cities.loc[~df_cities.city_id.isin(df_metropolie.city_id_metro)]\ndf_cities.head(5)\n##    city_id      name  population  latitude  longitude\n## 0       13  Prędocin         536  51.14791   21.32704\n## 1       16     Poraj         266  50.89962   23.99191\n## 2       37    Żyrzyn        1400  51.49918   22.09170\n## 3       41  Żyrardów       41179  52.04880   20.44599\n## 4       42   Żyraków        1400  50.08545   21.39622\n```\n:::\n\n\n### wlasciwy algorytm\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf_miasta_w_puli =df_cities\ncolumn_names = ['city_id','name','population'] +df_metropolie.columns.values.tolist()\ndf_miasta_wchloniete=pd.DataFrame(columns=column_names)\nstart = True\niteration =0\n\n\n# start funkcji\nwhile start == True:\n    df_metropolie_powiekszone=df_metropolie.append(df_miasta_wchloniete, ignore_index=True)\n    df_metropolie_powiekszone.population = df_metropolie_powiekszone.population.combine_first(df_metropolie_powiekszone.population_metro)\n    \n    df_metropolie_powiekszone_popul = df_metropolie_powiekszone.groupby(\n        ['city_id_metro','name_metro','population_metro','latitude_metro','longitude_metro',]).agg(\n        {'population':['sum']}).reset_index()\n    df_metropolie_powiekszone_popul.columns = df_metropolie_powiekszone_popul.columns.droplevel(1)\n    df_metropolie_powiekszone_popul['radius'] = radius(df_metropolie_powiekszone_popul['population'])\n    df_miasta_w_puli['key'] = 1\n    df_metropolie_powiekszone_popul['key'] = 1\n    df_x = pd.merge(df_miasta_w_puli, df_metropolie_powiekszone_popul, on='key', suffixes=('','_y')).drop(\"key\", 1)\n    #calculating distance between two coordinates \n    #https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude\n    distances_km = []\n    for row in df_x.itertuples():\n        distances_km.append(\n            haversine_distance_code( row.latitude, row.longitude ,row.latitude_metro, row.longitude_metro)\n        )\n    df_x['distance_km'] = distances_km\n    df_x = df_x[df_x.radius >= df_x.distance_km]\n    df_x['impact'] = _calcualate_metrocity_impact(df_x.radius,df_x.distance_km)\n    #stwierdzam do ktorej finalnie metropoli miejscowosci zostaje zaliczon\n    idx = df_x.groupby(['name','population'])['impact'].transform(max) == df_x['impact']\n    df_x = df_x[idx]\n    iteration+= 1\n    df_x['iteration_metro']=iteration\n    pre_rows_num=df_miasta_wchloniete.shape[0]\n    df_miasta_wchloniete=df_miasta_wchloniete.append(\n        df_x[column_names], ignore_index=True)\n    #pozbywam sie miast juz wchlonietych\n    indx = df_miasta_w_puli.city_id.isin(df_miasta_wchloniete.city_id)\n    df_miasta_w_puli = df_miasta_w_puli[~indx]\n    if pre_rows_num == df_miasta_wchloniete.shape[0]:\n        start = False\n## <string>:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n## <string>:10: SettingWithCopyWarning: \n## A value is trying to be set on a copy of a slice from a DataFrame.\n## Try using .loc[row_indexer,col_indexer] = value instead\n## \n## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ndf_metropolie_powiekszone_popul = df_metropolie_powiekszone.groupby(\n    ['city_id_metro','name_metro','population_metro','latitude_metro','longitude_metro',]).agg(\n    {'population':['sum']}).reset_index()\ndf_metropolie_powiekszone_popul.columns = df_metropolie_powiekszone_popul.columns.droplevel(1)\ndf_metropolie_powiekszone_popul['radius'] = radius(df_metropolie_powiekszone_popul['population'])\n\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n#finalne populacje metropoli\ndf_metropolie_powiekszone_popul.head(5)\n\n#przypisanie miast do metropoli wraz numerem iteracji\n##    city_id_metro name_metro  ...  population     radius\n## 0           3191     Warsaw  ...     5167905  97.494601\n## 1          12873     Lublin  ...      531712  37.739146\n## 2          25287    Wrocław  ...     1038518  56.178876\n## 3          27732   Szczecin  ...      589846  40.197589\n## 4          32047     Poznań  ...     1116528  58.484992\n## \n## [5 rows x 7 columns]\ndf_miasta_wchloniete.head(5)\n##   city_id           name  ... longitude_metro iteration_metro\n## 0      41       Żyrardów  ...        21.01178               1\n## 1     189       Zręczyce  ...        19.93658               1\n## 2     215       Żoliborz  ...        21.01178               1\n## 3     291          Złota  ...        21.01178               1\n## 4     339  Zielonki-Wieś  ...        21.01178               1\n## \n## [5 rows x 9 columns]\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}