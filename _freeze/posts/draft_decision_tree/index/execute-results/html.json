{
  "hash": "73eea205a0d13001b95eb0cd21f7db9e",
  "result": {
    "markdown": "---\ntitle: \"draft\"\ndate: \"2022-11-20\"\ntags: []\ncategories: []\ndraft: TRUE\ntoc: TRUE\neditor: source\n---\n\n\n\n\n\n::: {.cell}\n\n```\n## \n##          0          1 \n## 0.04969078 0.95030922\n```\n:::\n\n\n# dataset exploration\n\n# decision tree\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=100%}\n:::\n:::\n\n::: {.cell}\n\n```\n## Call:\n## rpart(formula = success ~ ., data = diamonds, method = \"class\")\n##   n= 37190 \n## \n##           CP nsplit rel error    xerror       xstd\n## 1 0.31818182      0 1.0000000 1.0000000 0.02267679\n## 2 0.04383117      1 0.6818182 0.6661255 0.01866886\n## 3 0.03896104      2 0.6379870 0.6125541 0.01792706\n## 4 0.01000000      4 0.5600649 0.5681818 0.01728517\n## \n## Variable importance\n##  depth random  table  price \n##     56     33      9      1 \n## \n## Node number 1: 37190 observations,    complexity param=0.3181818\n##   predicted class=1  expected loss=0.04969078  P(node) =1\n##     class counts:  1848 35342\n##    probabilities: 0.050 0.950 \n##   left son=2 (776 obs) right son=3 (36414 obs)\n##   Primary splits:\n##       depth  < 63.05     to the right, improve=1089.78800, (0 missing)\n##       random < 0.9000101 to the right, improve=1089.44800, (0 missing)\n##       table  < 62.1      to the right, improve= 230.00870, (0 missing)\n##       x      < 4.265     to the left,  improve=  21.74024, (0 missing)\n##       z      < 2.495     to the left,  improve=  17.51159, (0 missing)\n## \n## Node number 2: 776 observations,    complexity param=0.04383117\n##   predicted class=0  expected loss=0.121134  P(node) =0.02086582\n##     class counts:   682    94\n##    probabilities: 0.879 0.121 \n##   left son=4 (695 obs) right son=5 (81 obs)\n##   Primary splits:\n##       random < 0.8956954 to the right, improve=139.71310, (0 missing)\n##       price  < 15243.5   to the left,  improve= 17.07875, (0 missing)\n##       y      < 6.405     to the left,  improve= 15.41798, (0 missing)\n##       x      < 6.445     to the left,  improve= 14.28458, (0 missing)\n##       carat  < 1.095     to the left,  improve= 13.63918, (0 missing)\n##   Surrogate splits:\n##       price < 15243.5   to the left,  agree=0.909, adj=0.123, (0 split)\n##       y     < 7.995     to the left,  agree=0.899, adj=0.037, (0 split)\n##       carat < 2.015     to the left,  agree=0.898, adj=0.025, (0 split)\n##       z     < 5.445     to the left,  agree=0.898, adj=0.025, (0 split)\n##       x     < 7.895     to the left,  agree=0.897, adj=0.012, (0 split)\n## \n## Node number 3: 36414 observations,    complexity param=0.03896104\n##   predicted class=1  expected loss=0.03202065  P(node) =0.9791342\n##     class counts:  1166 35248\n##    probabilities: 0.032 0.968 \n##   left son=6 (4666 obs) right son=7 (31748 obs)\n##   Primary splits:\n##       random < 0.9000937 to the right, improve=508.07790, (0 missing)\n##       table  < 62.1      to the right, improve=221.75170, (0 missing)\n##       depth  < 57.95     to the left,  improve=101.26170, (0 missing)\n##       z      < 2.495     to the left,  improve= 20.45527, (0 missing)\n##       x      < 3.985     to the left,  improve= 18.95512, (0 missing)\n##   Surrogate splits:\n##       table < 62.1      to the right, agree=0.875, adj=0.025, (0 split)\n##       depth < 57.95     to the left,  agree=0.873, adj=0.012, (0 split)\n## \n## Node number 4: 695 observations\n##   predicted class=0  expected loss=0.01870504  P(node) =0.01868782\n##     class counts:   682    13\n##    probabilities: 0.981 0.019 \n## \n## Node number 5: 81 observations\n##   predicted class=1  expected loss=0  P(node) =0.002178005\n##     class counts:     0    81\n##    probabilities: 0.000 1.000 \n## \n## Node number 6: 4666 observations,    complexity param=0.03896104\n##   predicted class=1  expected loss=0.2498928  P(node) =0.1254638\n##     class counts:  1166  3500\n##    probabilities: 0.250 0.750 \n##   left son=12 (406 obs) right son=13 (4260 obs)\n##   Primary splits:\n##       table < 60.1      to the right, improve=162.50090, (0 missing)\n##       depth < 60.25     to the left,  improve= 92.13007, (0 missing)\n##       z     < 2.545     to the left,  improve= 39.25461, (0 missing)\n##       x     < 4.265     to the left,  improve= 38.88219, (0 missing)\n##       carat < 0.295     to the left,  improve= 36.52894, (0 missing)\n##   Surrogate splits:\n##       depth < 58.65     to the left,  agree=0.917, adj=0.052, (0 split)\n##       carat < 2.565     to the right, agree=0.913, adj=0.002, (0 split)\n##       x     < 8.785     to the right, agree=0.913, adj=0.002, (0 split)\n## \n## Node number 7: 31748 observations\n##   predicted class=1  expected loss=0  P(node) =0.8536703\n##     class counts:     0 31748\n##    probabilities: 0.000 1.000 \n## \n## Node number 12: 406 observations\n##   predicted class=0  expected loss=0.3226601  P(node) =0.01091691\n##     class counts:   275   131\n##    probabilities: 0.677 0.323 \n## \n## Node number 13: 4260 observations\n##   predicted class=1  expected loss=0.2091549  P(node) =0.1145469\n##     class counts:   891  3369\n##    probabilities: 0.209 0.791\n```\n:::\n\n\nBehind the scenes rpart() is automatically applying a range of cost complexity (α values to prune the tree). To compare the error for each α value, rpart() performs a 10-fold CV (by default). \n\n\n\nIn this example we find diminishing returns after 6 terminal nodes as illustrated in Figure below\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=100%}\n:::\n:::\n\ny-axis is the CV error, \nlower x-axis is the cost complexity (α) value, \nupper x-axis is the number of terminal nodes (i.e., tree size = |T|)\n\nYou may also notice the dashed line which goes through the point |T|=4. Breiman (1984) suggested that in actual practice, it’s common to instead use the smallest tree within 1 standard error (SE) of the minimum CV error (this is called the 1-SE rule). Thus, we could use a tree with 3 terminal nodes and reasonably expect to experience similar results within a small margin of error.\n\n\nTo illustrate the point of selecting a tree with 6 terminal nodes (or 4 if you go by the 1-SE rule), we can force rpart() to generate a full tree by setting cp = 0 (no penalty results in a fully grown tree). Figure below shows that after 4 terminal nodes, we see diminishing returns in error reduction as the tree grows deeper. Thus, we can significantly prune our tree and still achieve minimal expected error.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\nSo, by default, rpart() is performing some automated tuning, with an optimal subtree of 6 total splits, 6 terminal nodes, and a cross-validated SSE of 0.553.\n\n\n::: {.cell}\n\n```\n##           CP nsplit rel error    xerror       xstd\n## 1 0.31818182      0 1.0000000 1.0000000 0.02267679\n## 2 0.04383117      1 0.6818182 0.6661255 0.01866886\n## 3 0.03896104      2 0.6379870 0.6125541 0.01792706\n## 4 0.01000000      4 0.5600649 0.5681818 0.01728517\n```\n:::\n\n\n## dealing with imbalance\n### loss matrix\n\nYou can include a loss matrix, changing the relative importance of misclassifying a default as non-default versus a non-default as a default. You want to stress that misclassifying a default as a non-default should be penalized more heavily. \n\n\n::: {.cell}\n\n:::\n\n\nDoing this, you are constructing a 2x2-matrix with zeroes on the diagonal and changed loss penalties off-diagonal. The default loss matrix is all ones off-diagonal.\n\npenalization that is 20 times bigger when misclassifying an actual default as a non-default.\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=100%}\n:::\n:::\n\n\n\n\n### weights & costs\nThe weights is for rows (e.g. give higher weight to smaller class), the cost is for columns.\n\nweights\n\n    optional case weights.\n\ncost\n\n    a vector of non-negative costs, one for each variable in the model. Defaults to one for all variables. These are scalings to be applied when considering splits, so the improvement on splitting on a variable is divided by its cost in deciding which split to choose.\n\n\n## bagging\n\nBootstrapping  can be used to create an _ensemble_ of predictions. Bootstrap aggregating, also called _bagging_, is one of the first ensemble algorithms machine learning practitioners learn and is designed to improve the stability and accuracy of regression and classification algorithms. \nBy model averaging, bagging helps to reduce variance and minimize overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method.\n\n\n::: {.cell}\n\n```\n## Error in library(doParallel): there is no package called 'doParallel'\n## Error in library(caret): there is no package called 'caret'\n## Error in library(ipred): there is no package called 'ipred'\n## Error in loadNamespace(x): there is no package called 'rsample'\n## Error in loadNamespace(x): there is no package called 'rsample'\n## Error in loadNamespace(x): there is no package called 'rsample'\n```\n:::\n\n\n\nThe bagging() function comes from the ipred package and we use nbagg to control how many iterations to include in the bagged model and coob = TRUE indicates to use the OOB error rate. By default, bagging() uses rpart::rpart() for decision tree base learners but other base learners are available. Since bagging just aggregates a base learner, we can tune the base learner parameters as normal. Here, we pass parameters to rpart() with the control parameter and we build deep trees (no pruning) that require just two observations in a node to split. \n\n\n::: {.cell}\n\n```\n## Error in bagging(formula = success ~ ., data = diamonds, nbagg = 10, coob = TRUE, : could not find function \"bagging\"\n```\n:::\n\n\nOne thing to note is that typically, the more trees the better. As we add more trees we’re averaging over more high variance decision trees. Early on, we see a dramatic reduction in variance (and hence our error) but eventually the error will typically flatline and stabilize signaling that a suitable number of trees has been reached. Often, we need only 50–100 trees to stabilize the error (in other cases we may need 500 or more). For the Ames data we see that the error is stabilizing with just over 100 trees so we’ll likely not gain much improvement by simply bagging more trees.\n\n\n::: {.cell}\n\n```\n## Error in loadNamespace(x): there is no package called 'ranger'\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=100%}\n:::\n:::\n\n\n## grid search\n\n%% inspiration https://drsimonj.svbtle.com/grid-search-in-the-tidyverse %%\n\n### Training-Test Split\nTo help validate our hyperparameter combinations, we’ll split our data into training and test sets (in an 80/20 split):\n\n::: {.cell}\n\n:::\n\n\n### Create the Grid \n\n\nStep one for grid search is to define our hyperparameter combinations. Say we want to test a few values for minsplit and maxdepth. I like to setup the grid of their combinations in a tidy data frame with a list and cross_d as follows:\n\n\n::: {.cell}\n\n```\n## Error:\n## ! `cross_d()` was deprecated in purrr 0.2.3 and is now defunct.\n```\n:::\n\n\nNote that the list names are the names of the hyperparameters that we want to adjust in our model function.\n\n### Create a model function\n\nWe’ll be iterating down the gs data frame to use the hyperparameter values in a rpart model. The easiest way to handle this is to define a function that accepts a row of our data frame values and passes them correctly to our model. Here’s what I’ll use:\n\n\n::: {.cell}\n\n:::\n\n\n### Fit the models\nNow, to fit our models, use pmap to iterate down the values. The following is iterating through each row of our gs data frame, plugging the hyperparameter values for that row into our model.\n\n\n::: {.cell}\n\n```\n## Error in mutate(., fit = pmap(gs, mod)): object 'gs' not found\n```\n:::\n\n\n### Obtain accuracy\n\n\nNext, let’s assess the performance of each fit on our test data. To handle this efficiently, let’s write another small function:\n\n::: {.cell}\n\n:::\n\nNow apply this to each fit:\n\n::: {.cell}\n\n```\n## Error in mutate(., test_accuracy = map_dbl(fit, compute_accuracy, test_features, : object 'gs' not found\n## Error in eval(expr, envir, enclos): object 'gs_acc' not found\n## Error in rpart.plot(gs$fit[[1]], box.palette = \"RdBu\", shadow.col = \"gray\", : object 'gs' not found\n```\n:::\n\n\n\n## bootstraping\n\n\n%% inspiration https://rapidsurveys.io/learn/statistics/bootstrap/ %%\n\n::: {.cell}\n\n```\n## Error in loadNamespace(x): there is no package called 'rsample'\n## Error in eval(expr, envir, enclos): object 'df_bootstraping' not found\n## Error in library(modeldata): there is no package called 'modeldata'\n## Error in loadNamespace(x): there is no package called 'rsample'\n## Error in vctrs_vec_compat(.x, .purrr_user_env): object 'resample1' not found\n## Error in eval(expr, envir, enclos): object 'resample1' not found\n## Error in eval(expr, envir, enclos): object 'wa_churn' not found\n```\n:::\n\n\n## random Forest\n\n\n::: {.cell}\n\n```\n## Error in library(ranger): there is no package called 'ranger'\n## Error in library(h2o): there is no package called 'h2o'\n```\n:::\n\n\n# CV\n\nperform CV directly within certain ML functions:\n\n\n::: {.cell}\n\n```\n## Error in library(h2o): there is no package called 'h2o'\n## Error in h2o.init(): could not find function \"h2o.init\"\n## Error in loadNamespace(x): there is no package called 'AmesHousing'\n## Error in loadNamespace(x): there is no package called 'h2o'\n## Error in h2o.glm(x = \"Lot_Area\", y = \"Lot_Frontage\", training_frame = ames.h2o, : could not find function \"h2o.glm\"\n```\n:::\n\n\nOr externally as in the below chunk5. When applying it externally to an ML algorithm as below, we’ll need a process to apply the ML model to each resample, which we’ll also cover.\n\n\n::: {.cell}\n\n```\n## Error in loadNamespace(x): there is no package called 'rsample'\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}