---
title-block-banner: true
author: Łukasz Rąbalski
title: "Paralel processing with CPU"
description: Presentation of how different techniques of parralel processing in Python works
format:
  html:
    toc: true
    toc-location: left
    number-sections: true
    toc-depth: 3
    embed-resources: true
categories: ['Python','multiprocessing']
tags: []
editor: source
fig.height: 4
out.width: '100%'
include: TRUE  #prevents code and results from appearing in the finished file. R Markdown still runs the code in the chunk, and the results can be used by other chunks.
echo: TRUE  #echo = FALSE prevents code, but not the results from appearing in the finished file. This is a useful way to embed figures.
warning: FALSE
message: FALSE
error: FALSE
draft: TRUE
---

```{r eval=TRUE, include=FALSE}
library(reticulate)
myenvs=conda_list()
envname=myenvs$name[4]
use_condaenv(envname, required = TRUE)

Sys.setenv(RETICULATE_PYTHON = "/Users/lrabalski1/miniforge3/envs/everyday_use/bin/python")
reticulate::py_config()
```

```{python libraries, include=FALSE}

import time
from time import sleep
from random import random
import multiprocessing
from multiprocessing import Pool
from itertools import repeat
import numpy as np
import pandas as pd
from datetime import datetime

```

To check how different parallel processing techniques works I prepared function which looks liked that

```{python}
from analiza import map_function

import inspect
print(inspect.getsource(map_function))
```

In case of multiporcessing functions it's good practice to keep function in saved files in order to import them later.

See https://bugs.python.org/issue25053. For some reason Pool does not always work with objects not defined in an imported module. So you have to write your function into a different file and import the module.

<!--# https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerror  -->

# map vs imap

```{python}
from analiza import map_function

array_with_args = np.array([1,1], ndmin=2)
array_with_args = np.append(array_with_args,np.array([2,1], ndmin=2), axis=0)
array_with_args = np.append(array_with_args,np.array([3,0.5], ndmin=2), axis=0)
array_with_args = np.append(array_with_args,array_with_args, axis=0)
array_with_args = np.append(array_with_args,array_with_args, axis=0)


pd_results=pd.DataFrame(columns=['a','b','started'])
print(array_with_args)
if __name__ == '__main__':
    with Pool(processes=2) as pool:
        # call the same function with different data in parallel
        for result in pool.imap(map_function, array_with_args):
            print(1)
            # report the value to show progress
            pd_results = pd_results.append(result)

print(pd_results.sort_values('started', ascending=True))

array_with_args
```

```{python}
array_with_args.shape
```
